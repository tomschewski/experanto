{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b0faf41-e037-4a3b-8bdb-7ae89b4c9743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from experanto.datasets import ChunkDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a40f03fe-6b43-4b9d-8f62-030e145f7b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf, open_dict\n",
    "from experanto.configs import DEFAULT_CONFIG as cfg\n",
    "\n",
    "cfg.dataset.modality_config.screen.transforms.Resize.size = [144,144] \n",
    "cfg.dataset.modality_config.screen.interpolation.rescale_size = [144, 144]\n",
    "cfg.dataset.modality_config.screen.transforms.greyscale = True\n",
    "modality_cfg = cfg.dataset.modality_config\n",
    "\n",
    "# Extract only 'screen' and 'responses' or other modalities if necessecary for single session loading\n",
    "selected_modalities = OmegaConf.create({\n",
    "    'screen': modality_cfg.screen,\n",
    "    'responses': modality_cfg.responses\n",
    "})\n",
    "\n",
    "root_folder = '../data/allen_data'\n",
    "sampling_rate = 60\n",
    "chunk_size = 60 # since we also use video data we always use chunks of images to also consider temporal developements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "568cd9c1-9a7c-4f3e-99c9-1c8ca0382d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No metadata file found at ../data/allen_data/experiment_951980471_train/meta.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# sample modality config for a trainingset which includes screen and response interpolation\n",
    "\n",
    "train_dataset = ChunkDataset(root_folder=f'{root_folder}/experiment_951980471_train', global_sampling_rate=sampling_rate,\n",
    "            global_chunk_size=chunk_size, modality_config = selected_modalities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ac97e24-1e34-4df1-8d5c-69fc403bb8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No metadata file found at ../data/allen_data/experiment_951980473_val/meta.json\n"
     ]
    }
   ],
   "source": [
    "val_dataset = ChunkDataset(root_folder=f'{root_folder}/experiment_951980473_val', global_sampling_rate=sampling_rate,\n",
    "            global_chunk_size=chunk_size, modality_config = selected_modalities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7dee680-f6e7-48be-a2ce-fa550f0ada49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['screen', 'responses'])\n",
      "This is shape torch.Size([1, 60, 144, 144]) for modality screen\n",
      "This is shape torch.Size([60, 12]) for modality responses\n"
     ]
    }
   ],
   "source": [
    "# interpolation showcase using the dataset object\n",
    "sample = train_dataset[100]\n",
    "\n",
    "print(sample.keys())\n",
    "for key in sample.keys():\n",
    "    print(f'This is shape {sample[key].shape} for modality {key}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09491f58-0234-4073-afa5-12b730795a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating dataloaders based on the dataset objects\n",
    "\n",
    "batch_size = 50\n",
    "data_loaders = OrderedDict()\n",
    "\n",
    "data_loaders['train'] = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "data_loaders['val'] = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f1d3fb3-bbc7-4102-b74b-dd30d6b1a8e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('train',\n",
       "              <torch.utils.data.dataloader.DataLoader at 0x78f30686cfa0>),\n",
       "             ('val',\n",
       "              <torch.utils.data.dataloader.DataLoader at 0x78f30686ca60>)])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6c3a7b7-3db5-4045-90de-20d1b546c986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0:\n",
      "Screen Data: torch.Size([50, 1, 60, 144, 144])\n",
      "Responses: torch.Size([50, 60, 12])\n"
     ]
    }
   ],
   "source": [
    "# interpolation showcase using the data_loaders\n",
    "for batch_idx, batch_data in enumerate(data_loaders['train']):\n",
    "    # batch_data is a} dictionary with keys 'screen', 'responses', and 'timestamps'\n",
    "    screen_data = batch_data['screen']\n",
    "    responses = batch_data['responses']\n",
    "    \n",
    "    # Print or inspect the batch\n",
    "    print(f\"Batch {batch_idx}:\")\n",
    "    print(\"Screen Data:\", screen_data.shape)\n",
    "    print(\"Responses:\", responses.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659ffa90-b09c-4cdb-9655-bcd6bcad0c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
